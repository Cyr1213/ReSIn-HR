<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- Your custom style for line spacing -->
  <!-- <style>
      #answer-1 {
          line-height: 1;
          font-size: 1rem;
          margin-top: 0;
          margin-bottom: 0;
          padding: 0; /* This ensures no extra space around the text */
      }
  </style> -->
  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2" style="font-weight: bold; font-family: 'Noto Sans', sans-serif;">
            Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots
          </h1>
  
          <!-- Author Info -->
          <div class="is-size-5 publication-authors" style="margin-top: 1.5rem;">
            <p><strong>Author:</strong> Yanrong Chen</p>
            <p>
              <a href="mailto:Yanrong.Chen21@student.xjtlu.edu.cn">
                <span class="icon"><i class="fa fa-envelope"></i></span>
                Yanrong.Chen21@student.xjtlu.edu.cn
              </a>
            </p>
  
            <p style="margin-top: 1.5rem;"><strong>Supervisor:</strong> Xihan Bian</p>
            <p>
              <a href="mailto:Xihan.Bian@xjtlu.edu.cn">
                <span class="icon"><i class="fa fa-envelope"></i></span>
                Xihan.Bian@xjtlu.edu.cn
              </a>
            </p>
              <a target="_blank" href="assets/ReSIn-HR.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span><b>PDF</b></span>
                </a>
          </div>
  
        </div>
      </div>
    </div>
  </section>
  
  <section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p style="font-size: 125%">
                      As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction poses significant challenges. To further grow the integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three innovations: (1) A dual-channel emotion engine where LLM simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Dynamic time warping enhanced by duration-aware sequencing to temporally align speech output with kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO’s physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment than rule-based systems, achieved by coordinating vocal pitch (valence-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.
                  </div>
            </div>
        </div>
    </div>
</section>
<section class="section">
  <div class="container is-max-widescreen">
      <div class="rows">
          <div class="rows is-centered ">
              <div class="row is-full-width">
                  <h2 class="title is-2"><span class="dvima">Method</span></h2>

                  <!-- <img src="assets/images/eureka.png" class="interpolation-image" alt=""
                      style="display: block; margin-left: auto; margin-right: auto" />
                  <br> -->
                  <div class="columns is-centered has-text-centered">
                  <video poster="nao_methhod-poster.jpg" id="" autoplay controls muted width="90%" playbackRate=2.0 style="border-radius: 5px;">
                      <source src="videos/nao_method.mp4" type="video/mp4">
                  </video>
                  </div>
                  <span style="font-size: 125%">
                    Our framework synchronizes speech and gesture in real time through LLM planning, timing alignment, and physical feasibility checks.
                  </span>
              </div>
          </div>
      </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-widescreen">
    <div class="rows">
      <div class="rows is-centered">
        <div class="row is-full-width">
          <h2 class="title is-2"><span class="dvima">Experiments</span></h2>
        </div>
      </div>
    </div>
    <br>
      <div class="container is-max-widescreen">
          <div class="columns is-centered has-text-centered">
                <!-- <h2 class="title is-3">DrEureka 5-Minute Uncut Deployment Video</h2> -->
            </div>
            <br>

            <div class="columns is-centered has-text-centered">
          </div>
          <div class="rows">
            <div class="rows is-centered ">
              <div class="row is-full-width">
                <h3 class="title is-3"><span class="dvima">Emotion-Driven Gesture Comparison</span></h3>
      <p style="font-size: 125%">
        In this section, we compare gesture generation performance across different emotional states using real speech audio. Each case includes both predefined gestures and those generated by our system.
      </p>
    </div>
            </div>

  </div>
  </div>

  <div class="container is-max-widescreen">
    <div class="hero-body">
      <div class="container">

        <!-- Neutral Emotion Block -->
        <div class="video-group">
          <h3 class="title is-4">Emotion: Neutral</h3>
          <p><strong>Input Audio:</strong> 03-01-01-01-02-01-01.wav</p>
          <audio controls>
            <source src="videos/03-01-01-01-02-01-01.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
          <div class="video-grid">
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/netural_pre.mp4" type="video/mp4">
              </video>
              <p class="video-caption">Predefined Gesture</p>
            </div>
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/netural.mp4" type="video/mp4">
              </video>
              <p class="video-caption">ReSIn-HR(Ours) Generated Gesture</p>
            </div>
          </div>
        </div>

        <!-- Happy Emotion Block -->
        <div class="video-group">
          <h3 class="title is-4">Emotion: Happy</h3>
          <p><strong>Input Audio:</strong> 03-01-03-02-01-01-01.wav</p>
          <audio controls>
            <source src="videos/03-01-03-02-01-01-01.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
          <div class="video-grid">
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/happy_pre.mp4" type="video/mp4">
              </video>
              <p class="video-caption">Predefined Gesture</p>
            </div>
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/happy.mp4" type="video/mp4">
              </video>
              <p class="video-caption">ReSIn-HR(Ours) Generated Gesture</p>
            </div>
          </div>
        </div>

        <!-- Fearful Emotion Block -->
        <div class="video-group">
          <h3 class="title is-4">Emotion: Fearful</h3>
          <p><strong>Input Audio:</strong> 03-01-06-02-01-01-01.wav</p>
          <audio controls>
            <source src="videos/03-01-06-02-01-01-01.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
          <div class="video-grid">
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/fearful_pre.mp4" type="video/mp4">
              </video>
              <p class="video-caption">Predefined Gesture</p>
            </div>
            <div class="video-item">
              <video controls muted loop>
                <source src="videos/fearful.mp4" type="video/mp4">
              </video>
              <p class="video-caption">ReSIn-HR(Ours) Generated Gesture</p>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>

  <style>
    .video-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
      margin-top: 1rem;
    }

    .video-item {
      width: 100%;
      text-align: center;
    }

    video {
      width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 0 12px rgba(0, 0, 0, 0.1);
    }

    .video-caption {
      margin-top: 8px;
      font-size: 1rem;
      color: #333;
    }
  </style>

<div class="container is-max-widescreen">
  <div class="rows">
    <div class="rows is-centered">
      <div class="row is-full-width">
        <h2 class="title is-4"><span class="dvima">Emotion-Driven Gesture Demonstration</span></h2>
        <p style="font-size: 1.05rem;">
          Using manually written emotional utterances, we show how our system adapts gestures to speech content and emotional tone.
        </p>
      </div>
    </div>
  </div>

  <!-- Unified video layout -->
  <div class="video-grid1by3">
    <div class="video-item">
      <video controls muted loop>
        <source src="videos/happy_a.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Happy:</strong> "Hey buddy! I just got the job I wanted. Isn’t that amazing?"
      </p>
    </div>

    <div class="video-item">
      <video controls muted loop>
        <source src="videos/sad_a.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Sad:</strong> "I studied so hard, but still didn’t pass the exam. I feel really down."
      </p>
    </div>

    <div class="video-item">
      <video controls muted loop>
        <source src="videos/angry_a.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Angry:</strong> "Why didn’t anyone reply to my emails? I’m getting really frustrated."
      </p>
    </div>
  </div>
</div>

<style>
  .video-grid1by3 {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 24px;
    margin-top: 1.5rem;
    margin-left: auto;
    margin-right: auto;
  }

  .video-item {
    width: 100%;
    text-align: center;
  }

  video {
    width: 100%;
    height: auto;
    border-radius: 8px;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.15);
  }

  .video-caption {
    margin-top: 10px;
    font-size: 1rem;
    color: #333;
  }
</style>
<!-- Failures and Limitations Section -->
<div class="container is-max-widescreen" style="margin-top: 3rem">
  <div class="rows">
    <div class="rows is-centered">
      <div class="row is-full-width">
        <h2 class="title is-4"><span class="dvima">Failures and Limitations</span></h2>
        <p style="font-size: 1.05rem;">
          Below are some failure cases of our policy. In these cases, the robot lost stability due to center-of-mass shifts when swinging arms or stepping too far. This highlights the importance of integrating balance control during dynamic gesture execution.Future work will explore personalization, latency reduction, and multimodal extensions. This work contributes toward expressive, embodied human-robot interaction, with code and models to be released for the community.</p>
      </div>
    </div>
  </div>

  <div class="video-grid1by3">
    <div class="video-item">
      <video controls muted loop>
        <source src="videos/downandup.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Down and Up Swing:</strong> Balance is affected by vertical motion.
      </p>
    </div>

    <div class="video-item">
      <video controls muted loop>
        <source src="videos/back.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Backward Arm Movement:</strong> Shifting mass backwards causes instability.
      </p>
    </div>

    <div class="video-item">
      <video controls muted loop>
        <source src="videos/front.mp4" type="video/mp4">
      </video>
      <p class="video-caption">
        <strong>Forward Swing:</strong> Excessive forward force compromises stability.
      </p>
    </div>
  </div>
</div>

<style>
  .video-grid1by3 {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 24px;
    margin-top: 1.5rem;
    margin-left: auto;
    margin-right: auto;
  }
  .video-item {
    width: 100%;
    text-align: center;
  }
  video {
    width: 100%;
    height: auto;
    border-radius: 8px;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.15);
  }
  .video-caption {
    margin-top: 10px;
    font-size: 1rem;
    color: #333;
  }
</style>
</section>


</body>


</html>
